{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zakaria-bourouba/Data_Science/blob/main/TP6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq8xJ_UZh8MK"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Clé API à récuperer sur https://newsapi.org\n",
        "api_key = \"17dbe9704d5b425aa3b0224313457fef\"\n",
        "\n",
        "# sources d'actualités financieres\n",
        "sources = 'financial-post,the-wall-street-journal,bloomberg,the-washington-post,australian-financial-review,bbc-news,cnn'\n",
        "\n",
        "\n",
        "# on initialise les params pour appeler l'API\n",
        "def initialize_params(company_name: str):\n",
        "    last_day = datetime.today().strftime('%Y-%m-%d')\n",
        "    first_day = (datetime.today() - timedelta(days=20)).strftime('%Y-%m-%d')\n",
        "\n",
        "    return {\n",
        "        \"sources\": sources,\n",
        "        \"q\": company_name,\n",
        "        \"apiKey\": api_key,\n",
        "        \"language\": \"en\",\n",
        "        \"pageSize\": 100,\n",
        "        \"from\": first_day,\n",
        "        \"to\": last_day,\n",
        "    }\n",
        "\n",
        "# on sauvergarde les actualités récupérées dans un fihcier json\n",
        "def save_news(news_dict: dict, company_name: str, directory: str):\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    filepath = os.path.join(directory, f\"{company_name.lower()}_news.json\")\n",
        "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(news_dict, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "# on récupère les actualité d'unne entreprise donnée\n",
        "def get_news(company_name: str, path: str):\n",
        "    url = 'https://newsapi.org/v2/everything'\n",
        "    params = initialize_params(company_name)\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        news_data = response.json()\n",
        "        news_dict = {}\n",
        "\n",
        "        for article in news_data.get('articles', []):\n",
        "            title = article.get('title')\n",
        "            description = article.get('description')\n",
        "            published_at = article.get('publishedAt', '').split(\"T\")[0]\n",
        "            source_name = article.get('source', {}).get('name')\n",
        "            url = article.get('url')\n",
        "\n",
        "            if title and description and (company_name.lower() in title.lower() or company_name.lower() in description.lower()):\n",
        "                news_dict.setdefault(published_at, []).append({\n",
        "                    'title': title,\n",
        "                    'description': description,\n",
        "                    'publishedAt': published_at,\n",
        "                    'source': source_name,\n",
        "                    'url': url\n",
        "                })\n",
        "\n",
        "        save_news(news_dict, company_name, path)\n",
        "        return news_dict\n",
        "    else:\n",
        "        print(f\"Erreur lors de la récupération des actualités : {response.status_code}\")\n",
        "        return {}\n",
        "\n",
        "# on charge les actualités déjà enregistrées\n",
        "def load_existing_news(company_name: str, directory: str = \"news_data\") -> dict:\n",
        "    filepath = os.path.join(directory, f\"{company_name.lower()}_news.json\")\n",
        "    if os.path.exists(filepath):\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    return {}\n",
        "\n",
        "# on met à jour les actualités pour une entreprise\n",
        "def update_news(company_name: str, file_path: str):\n",
        "    existing_news = load_existing_news(company_name, file_path)\n",
        "    new_news = get_news(company_name, file_path)\n",
        "\n",
        "    for date, articles in new_news.items():\n",
        "        existing_news.setdefault(date, [])\n",
        "        for article in articles:\n",
        "            if not any(existing_article['title'] == article['title'] for existing_article in existing_news[date]):\n",
        "                existing_news[date].append(article)\n",
        "\n",
        "    os.makedirs(file_path, exist_ok=True)\n",
        "    output_file = os.path.join(file_path, f\"{company_name.lower()}_news.json\")\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        json.dump(existing_news, file, indent=4, ensure_ascii=False)\n",
        "    print(f\"News updated and saved to {output_file}\")\n",
        "\n",
        "\n",
        "# on récupére les actualités pour toutes les entreprises listées dans des fichiers CSV\n",
        "def get_news_all_companies(new_data_path: str, company_name_path: str):\n",
        "    filepaths = glob.glob(f\"{company_name_path}/*.csv\")\n",
        "\n",
        "    for file in filepaths:\n",
        "        filename = os.path.basename(file)\n",
        "        company_name = os.path.splitext(filename)[0].split('_')[0]\n",
        "        get_news(company_name, new_data_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    companies_name_path = \"Companies_historical_data\"\n",
        "    new_data_path = \"Companies_news_data\"\n",
        "    get_news_all_companies(new_data_path, companies_name_path)\n"
      ]
    }
  ]
}